{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53eb3a97",
   "metadata": {},
   "source": [
    "# Modeling <a id='Modeling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553a4b4",
   "metadata": {},
   "source": [
    "### 1 Table of Contents<a id='Contents'></a>\n",
    "* [Modeling](#Modeling)\n",
    "  * [1 Contents](#Contents)\n",
    "  * [2 Introduction](#2_Introduction)\n",
    "  * [3 Imports](#3_Imports)\n",
    "  * [4 Datasets and Dataloaders](#4_Datasets_and_Dataloaders)\n",
    "  * [5 SpatioTemporal Model](#5_SpatioTemporal_Model)\n",
    "  * [6 Spatial Model with Weather Features](#6_Spatial_Model_with_Weather_Features)\n",
    "  * [8 Best Model](#8_Best_Model)\n",
    "  * [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5121bd",
   "metadata": {},
   "source": [
    "### 2 Introduction <a id='2_Introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c5b74",
   "metadata": {},
   "source": [
    "In the last notebook, we created the tensor, split the data, and stored it in an h5py file. In this notebook, we'll be building our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257eea25",
   "metadata": {},
   "source": [
    "### 3 Imports <a id='3_Imports'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a82cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "from torch_geometric_temporal.nn.attention import stgcn\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import grid\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import h5py\n",
    "import googlemaps\n",
    "import os.path as osp\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835228f0",
   "metadata": {},
   "source": [
    "### 4 Datasets and Dataloaders <a id='4_Datasets_and_Dataloaders'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c8b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5GeometricTemporal(object):\n",
    "    def __init__(self, path, set_name):\n",
    "        self.set_name = set_name\n",
    "        self.path = path\n",
    "        super().__init__()\n",
    "        \n",
    "    def _get_edges(self):\n",
    "        edge_index, pos = grid(height = 50, width = 30)\n",
    "        self.edges = edge_index\n",
    "    \n",
    "    def _generate_task(self):\n",
    "        self.data = h5py.File(self.path, 'r')\n",
    "        self.set = self.data[self.set_name]\n",
    "        self.features = []\n",
    "        self.targets = []\n",
    "        for idx in range(self.set.shape[0]):\n",
    "            x = self.set[idx,:-1]\n",
    "            x = np.array(x)\n",
    "            x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "            x = np.transpose(x)\n",
    "            y = self.set[idx,-1]\n",
    "            y = np.array(y)\n",
    "            y = np.reshape(y, y.shape[0]*y.shape[1])\n",
    "            y = np.expand_dims(y, axis = 1)\n",
    "            y = np.append(y, y, 1)\n",
    "            for idx1 in range(y.shape[0]):\n",
    "                if (y[idx1,1] == 0):\n",
    "                    y[idx1,1] = 1\n",
    "                else:\n",
    "                    y[idx1,1] = 0\n",
    "            y[:, [1, 0]] = y[:, [0, 1]]\n",
    "            self.features.append(x)\n",
    "            self.targets.append(y)\n",
    "            \n",
    "    def get_dataset(self):\n",
    "        self._get_edges()\n",
    "        self._generate_task()\n",
    "        dataset = StaticGraphTemporalSignal(self.edges, None, self.features, self.targets)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "607ed8ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_temporal_loader = H5GeometricTemporal('../Data/LA_windowed_split.hdf5', 'train_windowed')\n",
    "train_temporal = train_temporal_loader.get_dataset()\n",
    "test_temporal_loader = H5GeometricTemporal('../Data/LA_windowed_split.hdf5', 'test_windowed')\n",
    "test_temporal = test_temporal_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91e30ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Geometric(Dataset):\n",
    "    def __init__(self, root, set_name, transform = None, pre_transform = None):\n",
    "        self.set_name = set_name\n",
    "        self.processed_file_names = []\n",
    "        if (self.set_name == 'train'):\n",
    "            for idx in range(78888):\n",
    "                self.processed_file_names.append(f'data_train_{idx}.pt')\n",
    "        else:\n",
    "            for idx in range(26296):\n",
    "                self.processed_file_names.append(f'data_test_{idx}.pt')\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        \n",
    "    def raw_file_names(self):\n",
    "        return 'LA_data_split_random.hdf5'\n",
    "\n",
    "    def processed_file_names(self):\n",
    "        return self.processed_file_names\n",
    "\n",
    "    def process(self):\n",
    "        self.data = h5py.File(self.raw_paths[0], 'r')\n",
    "        self.set = self.data[self.set_name]\n",
    "        edge_index, pos = grid(height = 50, width = 30, device = 'cuda:0')\n",
    "        for idx in range(self.set.shape[0]):\n",
    "            x = self.set[idx,:,:,1:]\n",
    "            x = t.tensor(x).reshape(x.shape[0]*x.shape[1], x.shape[2])\n",
    "            y = self.set[idx,:,:,0]\n",
    "            y = t.tensor(y).reshape(y.shape[0]*y.shape[1])\n",
    "            y = y[:,None]\n",
    "            y = t.cat((y, y), dim = 1)\n",
    "            for idx1 in range(y.shape[0]):\n",
    "                if (y[idx1,1] == 0):\n",
    "                    y[idx1,1] = 1\n",
    "                else:\n",
    "                    y[idx1,1] = 0\n",
    "            y[:, [1, 0]] = y[:, [0, 1]]\n",
    "            \n",
    "            data = Data(x = x,\n",
    "                        edge_index = edge_index,\n",
    "                        y = y\n",
    "                       )\n",
    "            t.save(data, osp.join(self.processed_dir, f'data_{self.set_name}_{idx}.pt'))\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        data = t.load(osp.join(self.processed_dir, f'data_{self.set_name}_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70bb69be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_random = H5Geometric('../Data/', 'train')\n",
    "train_random_loader = DataLoader(train_random, shuffle = True, batch_size = 8)\n",
    "test_random = H5Geometric('../Data/', 'test')\n",
    "test_random_loader = DataLoader(test_random, shuffle = False, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc8b9952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26bf469",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACC(pred, actual):\n",
    "    correct_trues = np.logical_and(np.array(pred[:,1].cpu()), np.array(actual[:,1].cpu())).sum()\n",
    "    total_trues = np.array(actual[:,1].cpu()).sum()\n",
    "    return total_trues, correct_trues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afde74",
   "metadata": {},
   "source": [
    "### 5 SpatioTemporal Model <a id='5_SpatioTemporal_Model'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5678001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(nn.Module):\n",
    "    def __init__(self, node_features, num_classes):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent_1 = GConvGRU(node_features, 32, 5)\n",
    "        self.recurrent_2 = GConvGRU(32, 16, 5)\n",
    "        self.linear = nn.Linear(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.recurrent_1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.recurrent_2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a06d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentGCN(node_features = 5, num_classes = 2)\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight = t.FloatTensor([1.0, 200.0]).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5efbb407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "eval\n",
      "train\n",
      "test\n",
      "Epoch 0: train BCE 0.7714, test BCE 0.7133\n",
      "Epoch 0: train ACC 100.0000, test ACC 100.0000\n",
      "Training\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y_pred, y)\n\u001b[0;32m     17\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 18\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     20\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\TestEnv\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "train_BCE_totals = []\n",
    "train_ACC_totals = []\n",
    "test_BCE_totals = []\n",
    "test_ACC_totals = []\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    print('Training')\n",
    "    for snapshot in train_temporal:\n",
    "        x = snapshot.x.cuda()\n",
    "        edge_index = snapshot.edge_index.cuda()\n",
    "        edge_weight = snapshot.edge_weight\n",
    "        y = snapshot.y.cuda()\n",
    "        y_pred = model(x, edge_index, edge_weight)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    gc.collect()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    print(\"eval\")\n",
    "    with t.no_grad():\n",
    "        train_BCEs = []\n",
    "        train_total_positives = 0\n",
    "        train_total_correct_positives = 0\n",
    "        test_BCEs = []\n",
    "        test_total_positives = 0\n",
    "        test_total_correct_positives = 0\n",
    "        print(\"train\")\n",
    "        for snapshot in train_temporal:\n",
    "            x = snapshot.x.cuda() \n",
    "            edge_index = snapshot.edge_index.cuda()\n",
    "            edge_weight = snapshot.edge_weight\n",
    "            y = snapshot.y.cuda()\n",
    "            y_pred = model(x, edge_index, edge_weight)\n",
    "            train_BCE = loss_fn(y_pred, y)\n",
    "            train_BCEs.append(train_BCE.cpu())\n",
    "            actual_positives, correct_positives = ACC(y_pred, y)\n",
    "            train_total_positives += actual_positives\n",
    "            train_total_correct_positives += correct_positives\n",
    "        print(\"test\")\n",
    "        for snapshot in test_temporal:\n",
    "            x = snapshot.x.cuda() \n",
    "            edge_index = snapshot.edge_index.cuda()\n",
    "            edge_weight = snapshot.edge_weight\n",
    "            y = snapshot.y.cuda()\n",
    "            y_pred = model(x, edge_index, edge_weight)\n",
    "            test_BCE = loss_fn(y_pred, y)\n",
    "            test_BCEs.append(test_BCE.cpu())\n",
    "            actual_positives, correct_positives = ACC(y_pred, y)\n",
    "            test_total_positives += actual_positives\n",
    "            test_total_correct_positives += correct_positives\n",
    "        train_BCE_avg = np.array(train_BCEs).mean()\n",
    "        train_ACC_avg = (train_total_correct_positives / train_total_positives) * 100\n",
    "        test_BCE_avg = np.array(test_BCEs).mean()\n",
    "        test_ACC_avg = (test_total_correct_positives / test_total_positives) * 100\n",
    "    train_BCE_totals.append(train_BCE_avg)\n",
    "    train_ACC_totals.append(train_ACC_avg)\n",
    "    test_BCE_totals.append(test_BCE_avg)\n",
    "    test_ACC_totals.append(test_ACC_avg)\n",
    "    print(\"Epoch %d: train BCE %.4f, test BCE %.4f\" % (epoch, train_BCE_avg, test_BCE_avg))\n",
    "    print(\"Epoch %d: train ACC %.4f, test ACC %.4f\" % (epoch, train_ACC_avg, test_ACC_avg))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (14, 12));\n",
    "ax[0].plot(train_BCE_totals, train_ACC_totals)\n",
    "ax[0].set_xlabel('BCE')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].title.set_text('Train')\n",
    "ax[1].plot(test_BCE_totals, test_ACC_totals)\n",
    "ax[1].set_xlabel('BCE')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].title.set_text('Test')\n",
    "\n",
    "fig.suptitle('Accuracy vs Binary Cross Entropy Loss: Temporal GNN')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b38f231",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f3b7d",
   "metadata": {},
   "source": [
    "### 6 Spatial Model with Weather Features <a id='6_Spatial_Model_with_Weather_Features'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(11, 16)\n",
    "        self.conv2 = GCNConv(16, 11)\n",
    "        self.linear = nn.Linear(11, 2)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GCN()\n",
    "model2.cuda()\n",
    "optimizer = optim.Adam(model2.parameters(), lr = 0.001)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight = t.FloatTensor([1.0, 200.0].cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81979574",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "train_BCE_totals = []\n",
    "train_ACC_totals = []\n",
    "test_BCE_totals = []\n",
    "test_ACC_totals = []\n",
    "for epoch in range(n_epochs):\n",
    "    #Training\n",
    "    model2.train()\n",
    "    for data in train_random_loader:\n",
    "        x = data.x.type(t.cuda.FloatTensor)\n",
    "        edge_index = data.edge_index.type(t.cuda.LongTensor)\n",
    "        y = data.y.type(t.cuda.FloatTensor)\n",
    "        y_pred = model2(x, edge_index)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    model2.eval()\n",
    "    with t.no_grad():\n",
    "        train_BCEs = []\n",
    "        train_total_positives = 0\n",
    "        train_total_correct_positives = 0\n",
    "        test_BCEs = []\n",
    "        test_total_positives = 0\n",
    "        test_total_correct_positives = 0\n",
    "        for data in train_random_loader:\n",
    "            x = data.x.type(t.cuda.FloatTensor)\n",
    "            edge_index = data.edge_index.type(t.cuda.LongTensor)\n",
    "            y = data.y.type(t.cuda.FloatTensor)\n",
    "            y_pred = model2(x, edge_index)\n",
    "            train_BCE = loss_fn(y_pred, y)\n",
    "            train_BCEs.append(train_BCE.cpu())\n",
    "            actual_positives, correct_positives = ACC(y_pred, y)\n",
    "            train_total_positives += actual_positives\n",
    "            train_total_correct_positives += correct_positives\n",
    "        for data in test_random_loader:\n",
    "            x = data.x.type(t.cuda.FloatTensor)\n",
    "            edge_index = data.edge_index.type(t.cuda.LongTensor)\n",
    "            y = data.y.type(t.cuda.FloatTensor)\n",
    "            y_pred = model2(x, edge_index)\n",
    "            test_BCE = loss_fn(y_pred, y)\n",
    "            test_BCEs.append(test_BCE.cpu())\n",
    "            actual_positives, correct_positives = ACC(y_pred, y)\n",
    "            test_total_positives += actual_positives\n",
    "            test_total_correct_positives += correct_positives\n",
    "        train_BCE_avg = np.array(train_BCEs).mean()\n",
    "        train_ACC_avg = (train_total_correct_positives / train_total_positives) * 100\n",
    "        test_BCE_avg = np.array(test_BCEs).mean()\n",
    "        test_ACC_avg = (test_total_correct_positives / test_total_positives) * 100\n",
    "    train_BCE_totals.append(train_BCE_avg)\n",
    "    train_ACC_totals.append(train_ACC_avg)\n",
    "    test_BCE_totals.append(test_BCE_avg)\n",
    "    test_ACC_totals.append(test_ACC_avg)\n",
    "    print(\"Epoch %d: train BCE %.4f, test BCE %.4f\" % (epoch, train_BCE_avg, test_BCE_avg))\n",
    "    print(\"Epoch %d: train ACC %.4f, test ACC %.4f\" % (epoch, train_ACC_avg, test_ACC_avg))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e687dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (14, 12));\n",
    "ax[0].plot(train_BCE_totals, train_ACC_totals)\n",
    "ax[0].set_xlabel('BCE')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].title.set_text('Train')\n",
    "ax[1].plot(test_BCE_totals, test_ACC_totals)\n",
    "ax[1].set_xlabel('BCE')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].title.set_text('Test')\n",
    "\n",
    "fig.suptitle('Accuracy vs Binary Cross Entropy Loss: GNN with Weather Features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7962ced6",
   "metadata": {},
   "source": [
    "### 8 Best Model <a id='8_Best_Model'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b522967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93595d4c",
   "metadata": {},
   "source": [
    "### Conclusion <a id='Conclusion'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57980d1",
   "metadata": {},
   "source": [
    "The final model..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
