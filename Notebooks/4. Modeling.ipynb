{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53eb3a97",
   "metadata": {},
   "source": [
    "# Modeling <a id='Modeling'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553a4b4",
   "metadata": {},
   "source": [
    "### 1 Table of Contents<a id='Contents'></a>\n",
    "* [Modeling](#Modeling)\n",
    "  * [1 Contents](#Contents)\n",
    "  * [2 Introduction](#2_Introduction)\n",
    "  * [3 Imports](#3_Imports)\n",
    "  * [4 Datasets and Dataloaders](#4_Datasets_and_Dataloaders)\n",
    "  * [5 SpatioTemporal Model](#5_SpatioTemporal_Model)\n",
    "  * [6 Spatial Model with Weather Features](#6_Spatial_Model_with_Weather_Features)\n",
    "  * [8 Best Model](#8_Best_Model)\n",
    "  * [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5121bd",
   "metadata": {},
   "source": [
    "### 2 Introduction <a id='2_Introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c5b74",
   "metadata": {},
   "source": [
    "In the last notebook, we created the tensor, split the data, and stored it in an h5py file. In this notebook, we'll be building our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257eea25",
   "metadata": {},
   "source": [
    "### 3 Imports <a id='3_Imports'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a82cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import numpy as np\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric_temporal.nn.recurrent import GConvGRU\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "from torch_geometric_temporal.nn.attention import stgcn\n",
    "from torch_geometric.data import Dataset, Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import grid\n",
    "from sklearn.metrics import classification_report\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import gc\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import h5py\n",
    "import googlemaps\n",
    "import os.path as osp\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835228f0",
   "metadata": {},
   "source": [
    "### 4 Datasets and Dataloaders <a id='4_Datasets_and_Dataloaders'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10c8b53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5GeometricTemporal(object):\n",
    "    def __init__(self, path, set_name):\n",
    "        self.set_name = set_name\n",
    "        self.path = path\n",
    "        super().__init__()\n",
    "        \n",
    "    def _get_edges(self):\n",
    "        edge_index, pos = grid(height = 50, width = 30)\n",
    "        self.edges = edge_index\n",
    "    \n",
    "    def _generate_task(self):\n",
    "        self.data = h5py.File(self.path, 'r')\n",
    "        self.set = self.data[self.set_name]\n",
    "        self.features = []\n",
    "        self.targets = []\n",
    "        for idx in range(self.set.shape[0]):\n",
    "            x = self.set[idx,:-1]\n",
    "            x = np.array(x)\n",
    "            x = np.reshape(x, (x.shape[0], x.shape[1]*x.shape[2]))\n",
    "            x = np.transpose(x)\n",
    "            y = self.set[idx,-1]\n",
    "            y = np.array(y)\n",
    "            y = np.reshape(y, y.shape[0]*y.shape[1])\n",
    "            y = np.expand_dims(y, axis = 1)\n",
    "            self.features.append(x)\n",
    "            self.targets.append(y)\n",
    "            \n",
    "    def get_dataset(self):\n",
    "        self._get_edges()\n",
    "        self._generate_task()\n",
    "        dataset = StaticGraphTemporalSignal(self.edges, None, self.features, self.targets)\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ed8ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_temporal_loader = H5GeometricTemporal('../Data/LA_windowed_split.hdf5', 'train_windowed')\n",
    "train_temporal = train_temporal_loader.get_dataset()\n",
    "test_temporal_loader = H5GeometricTemporal('../Data/LA_windowed_split.hdf5', 'test_windowed')\n",
    "test_temporal = test_temporal_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9591970",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e30ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Geometric(Dataset):\n",
    "    def __init__(self, root, set_name, transform = None, pre_transform = None):\n",
    "        self.set_name = set_name\n",
    "        self.processed_file_names = []\n",
    "        if (self.set_name == 'train'):\n",
    "            for idx in range(78888):\n",
    "                self.processed_file_names.append(f'data_train_{idx}.pt')\n",
    "        else:\n",
    "            for idx in range(26296):\n",
    "                self.processed_file_names.append(f'data_test_{idx}.pt')\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        \n",
    "    def raw_file_names(self):\n",
    "        return 'LA_data_split_random.hdf5'\n",
    "\n",
    "    def processed_file_names(self):\n",
    "        return self.processed_file_names\n",
    "\n",
    "    def process(self):\n",
    "        self.data = h5py.File(self.raw_paths[0], 'r')\n",
    "        self.set = self.data[self.set_name]\n",
    "        edge_index, pos = grid(height = 50, width = 30, device = 'cuda:0')\n",
    "        for idx in range(self.set.shape[0]):\n",
    "            x = self.set[idx,:,:,1:]\n",
    "            x = t.tensor(x).reshape(x.shape[0]*x.shape[1], x.shape[2])\n",
    "            y = self.set[idx,:,:,0]\n",
    "            y = t.tensor(y).reshape(y.shape[0]*y.shape[1])\n",
    "            y = y[:,None]\n",
    "            \n",
    "            data = Data(x = x,\n",
    "                        edge_index = edge_index,\n",
    "                        y = y\n",
    "                       )\n",
    "            t.save(data, osp.join(self.processed_dir, f'data_{self.set_name}_{idx}.pt'))\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        data = t.load(osp.join(self.processed_dir, f'data_{self.set_name}_{idx}.pt'))\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bb69be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_random = H5Geometric('../Data/', 'train')\n",
    "train_random_loader = DataLoader(train_random, shuffle = True, batch_size = 8)\n",
    "test_random = H5Geometric('../Data/', 'test')\n",
    "test_random_loader = DataLoader(test_random, shuffle = False, batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8b9952",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b02a4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACC(pred, actual):\n",
    "    actual_positives = 0\n",
    "    correct_positives = 0\n",
    "    for idx in range(pred.shape[0]):\n",
    "        if (actual[idx] == 1):\n",
    "            actual_positives += 1\n",
    "            if (pred[idx] == 1):\n",
    "                correct_positives += 1\n",
    "    return actual_positives, correct_positives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afde74",
   "metadata": {},
   "source": [
    "### 5 SpatioTemporal Model <a id='5_SpatioTemporal_Model'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5678001",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(nn.Module):\n",
    "    def __init__(self, node_features, num_classes):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent_1 = GConvGRU(node_features, 32, 5)\n",
    "        self.recurrent_2 = GConvGRU(32, 16, 5)\n",
    "        self.linear = nn.Linear(16, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        x = self.recurrent_1(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.recurrent_2(x, edge_index, edge_weight)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.linear(x)\n",
    "        x = t.sigmoid(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a06d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RecurrentGCN(node_features = 5, num_classes = 2)\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efbb407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "train_BCE_totals = []\n",
    "train_ACC_totals = []\n",
    "test_BCE_totals = []\n",
    "test_ACC_totals = []\n",
    "for epoch in range(n_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for snapshot in train_temporal:\n",
    "        x = snapshot.x.cuda()\n",
    "        edge_index = snapshot.edge_index.cuda()\n",
    "        edge_weight = snapshot.edge_weight\n",
    "        y = snapshot.y.cuda()\n",
    "        y_pred = model(x, edge_index, edge_weight)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    gc.collect()\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with t.no_grad():\n",
    "        train_BCEs = []\n",
    "        train_total_positives = 0\n",
    "        train_total_correct_positives = 0\n",
    "        test_BCEs = []\n",
    "        test_total_positives = 0\n",
    "        test_total_correct_positives = 0\n",
    "        for snapshot in train_temporal:\n",
    "            x = snapshot.x.cuda() \n",
    "            edge_index = snapshot.edge_index.cuda()\n",
    "            edge_weight = snapshot.edge_weight\n",
    "            y = snapshot.y.cuda()\n",
    "            y_pred = model(x, edge_index, edge_weight)\n",
    "            train_BCE = loss_fn(y_pred, y)\n",
    "            train_BCEs.append(train_BCE.cpu())\n",
    "            actual_positives, correct_positives = ACC(y_pred, y)\n",
    "            train_total_positives += actual_positives\n",
    "            train_total_correct_positives += correct_positives\n",
    "        for snapshot in test_temporal:\n",
    "            x = snapshot.x.cuda()\n",
    "            edge_index = snapshot.edge_index.cuda()\n",
    "            edge_weight = snapshot.edge_weight\n",
    "            y = snapshot.y.cuda()\n",
    "            y_pred = model(x, edge_index, edge_weight)\n",
    "            test_BCE = loss_fn(y_pred, y)\n",
    "            test_BCEs.append(test_BCE.cpu())\n",
    "            actual_positives, correct_positives = ACC(y_pred, y)\n",
    "            test_total_positives += actual_positives\n",
    "            test_total_correct_positives += correct_positives\n",
    "        train_BCE_avg = np.array(train_BCEs).mean()\n",
    "        train_ACC_avg = (train_total_correct_positives / train_total_positives) * 100\n",
    "        test_BCE_avg = np.array(test_BCEs).mean()\n",
    "        test_ACC_avg = (test_total_correct_positives / test_total_positives) * 100\n",
    "    train_BCE_totals.append(train_BCE_avg)\n",
    "    train_ACC_totals.append(train_ACC_avg)\n",
    "    test_BCE_totals.append(test_BCE_avg)\n",
    "    test_ACC_totals.append(test_ACC_avg)\n",
    "    print(\"Epoch %d: train BCE %.4f, test BCE %.4f\" % (epoch, train_BCE_avg, test_BCE_avg))\n",
    "    print(\"Epoch %d: train ACC %.4f, test ACC %.4f\" % (epoch, train_ACC_avg, test_ACC_avg))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72529a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (14, 12));\n",
    "ax[0].plot(train_BCE_totals, train_ACC_totals)\n",
    "ax[0].set_xlabel('BCE')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].title.set_text('Train')\n",
    "ax[1].plot(test_BCE_totals, test_ACC_totals)\n",
    "ax[1].set_xlabel('BCE')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].title.set_text('Test')\n",
    "\n",
    "fig.suptitle('Accuracy vs Binary Cross Entropy Loss: Temporal GNN')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5793ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f3b7d",
   "metadata": {},
   "source": [
    "### 6 Spatial Model with Weather Features <a id='6_Spatial_Model_with_Weather_Features'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(11, 16)\n",
    "        self.conv2 = GCNConv(16, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, train):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=train)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = t.sigmoid(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d7d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = GCN()\n",
    "model2.cuda()\n",
    "optimizer = optim.Adam(model2.parameters(), lr = 0.001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81979574",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "train_BCE_totals = []\n",
    "train_ACC_totals = []\n",
    "test_BCE_totals = []\n",
    "test_ACC_totals = []\n",
    "for epoch in range(n_epochs):\n",
    "    #Training\n",
    "    model2.train()\n",
    "    for data in train_random_loader:\n",
    "        x = data.x.type(t.cuda.FloatTensor)\n",
    "        edge_index = data.edge_index.type(t.cuda.LongTensor)\n",
    "        y = data.y.type(t.cuda.FloatTensor)\n",
    "        y_pred = model2(x, edge_index, True)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # Validation\n",
    "    model2.eval()\n",
    "    with t.no_grad():\n",
    "        train_BCEs = []\n",
    "        train_total_positives = 0\n",
    "        train_total_correct_positives = 0\n",
    "        test_BCEs = []\n",
    "        test_total_positives = 0\n",
    "        test_total_correct_positives = 0\n",
    "        for data in train_random_loader:\n",
    "            x = data.x.type(t.cuda.FloatTensor)\n",
    "            edge_index = data.edge_index.type(t.cuda.LongTensor)\n",
    "            y = data.y.type(t.cuda.FloatTensor)\n",
    "            y_pred = model2(x, edge_index, False)\n",
    "            train_BCE = loss_fn(y_pred, y)\n",
    "            train_BCEs.append(train_BCE.cpu())\n",
    "            actual_positives, correct_positives = ACC(y_pred, y)\n",
    "            train_total_positives += actual_positives\n",
    "            train_total_correct_positives += correct_positives\n",
    "        for data in test_random_loader:\n",
    "            x = data.x.type(t.cuda.FloatTensor)\n",
    "            edge_index = data.edge_index.type(t.cuda.LongTensor)\n",
    "            y = data.y.type(t.cuda.FloatTensor)\n",
    "            y_pred = model2(x, edge_index, False)\n",
    "            test_BCE = loss_fn(y_pred, y)\n",
    "            test_BCEs.append(test_BCE.cpu())\n",
    "            actual_positives, correct_positives = ACC(y_pred, y)\n",
    "            test_total_positives += actual_positives\n",
    "            test_total_correct_positives += correct_positives\n",
    "        train_BCE_avg = np.array(train_BCEs).mean()\n",
    "        train_ACC_avg = (train_total_correct_positives / train_total_positives) * 100\n",
    "        test_BCE_avg = np.array(test_BCEs).mean()\n",
    "        test_ACC_avg = (test_total_correct_positives / test_total_positives) * 100\n",
    "    train_BCE_totals.append(train_BCE_avg)\n",
    "    train_ACC_totals.append(train_ACC_avg)\n",
    "    test_BCE_totals.append(test_BCE_avg)\n",
    "    test_ACC_totals.append(test_ACC_avg)\n",
    "    print(\"Epoch %d: train BCE %.4f, test BCE %.4f\" % (epoch, train_BCE_avg, test_BCE_avg))\n",
    "    print(\"Epoch %d: train ACC %.4f, test ACC %.4f\" % (epoch, train_ACC_avg, test_ACC_avg))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e687dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (14, 12));\n",
    "ax[0].plot(train_BCE_totals, train_ACC_totals)\n",
    "ax[0].set_xlabel('BCE')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].title.set_text('Train')\n",
    "ax[1].plot(test_BCE_totals, test_ACC_totals)\n",
    "ax[1].set_xlabel('BCE')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].title.set_text('Test')\n",
    "\n",
    "fig.suptitle('Accuracy vs Binary Cross Entropy Loss: GNN with Weather Features')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7962ced6",
   "metadata": {},
   "source": [
    "### 8 Best Model <a id='8_Best_Model'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b522967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93595d4c",
   "metadata": {},
   "source": [
    "### Conclusion <a id='Conclusion'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57980d1",
   "metadata": {},
   "source": [
    "The final model..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
