{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53eb3a97",
   "metadata": {},
   "source": [
    "# Pre-Processing and Feature Engineering<a id='Pre-Processing_and_Feature_Engineering'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a553a4b4",
   "metadata": {},
   "source": [
    "### 1 Table of Contents<a id='Contents'></a>\n",
    "* [Pre-Processing and Feature Engineering](#Pre-Processing_and_Feature_Engineering)\n",
    "  * [1 Contents](#Contents)\n",
    "  * [2 Introduction](#2_Introduction)\n",
    "  * [3 Imports](#3_Imports)\n",
    "  * [4 Load Data](#4_Load_Data)\n",
    "  * [5 Creating the Tensor](#5_Creating_the_Tensor)\n",
    "  * [6 Split the Data](#6_Split_the_Data)\n",
    "  * [7 Saving as an H5PY File](#7_Saving_as_an_H5PY_File)\n",
    "  * [8 Creating Windowed Datasets](#8_Creating_Windowed_Datasets)\n",
    "  * [9 Conclusion](#9_Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb885e6",
   "metadata": {},
   "source": [
    "### 2 Introduction<a id='2_Introduction'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60918e16",
   "metadata": {},
   "source": [
    "In the last notebook, the spatial and temporal resolution that will be used for the tensors was decided. For spatial resolution, a 50x30 array will be used.  Traffic volume data was found from the Los Angeles Department of Transportation to be used as one of the tensor layers. The other layers will be made up of weather variables such as temperature, visibility, and cloud cover. The target is a 1 or 0 for each grid cell, representing whether an accident occured or not. \n",
    "\n",
    "In this notebook, we will build the complete tensor of weather, traffic, and collision data. The tensor will then be split into test and train sets and a baseline performance for the model will be determined."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04975de",
   "metadata": {},
   "source": [
    "### 3 Imports<a id='3_Imports'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "571c0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch as t\n",
    "import torch.utils.data as dt\n",
    "import gc\n",
    "import os\n",
    "import math\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e551dc2",
   "metadata": {},
   "source": [
    "### 4 Load Data<a id='4_Load_Data'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c7f4825",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_collisions = pd.read_csv('../Data/LA_collisions.csv', index_col = 'Unnamed: 0')\n",
    "LA_weather = pd.read_csv('../Data/LA_weather_cleaned.csv', index_col = 'Unnamed: 0')\n",
    "LA_traffic = pd.read_csv('../Data/LA_traffic.csv', index_col = 'Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ace474c",
   "metadata": {},
   "source": [
    "### 5 Creating the Tensor <a id='5_Creating_the_Tensor'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d760ff",
   "metadata": {},
   "source": [
    "The unmerged dataframes will be used to fill the tensor, as the unmerged weather dataframe (which contains most of the input features) has complete hourly records of weather features dating back to 2006, the other input feature is the count data in the traffic dataframe, and the output feature is the presence of a collision in the collisions dataframe. First, to determine the columns in each of our dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9ab303c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['primary_road', 'secondary_road', 'intersection', 'side_of_highway',\n",
       "       'severity', 'type', 'pedestrian', 'bicycle', 'motorcycle', 'truck',\n",
       "       'same_day_crashes', 'same_road_crashes', 'latitude', 'longitude',\n",
       "       'datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_collisions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2914e7ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['dt', 'temp', 'visibility', 'dew_point', 'temp_min', 'temp_max',\n",
       "       'pressure', 'humidity', 'wind_speed', 'wind_deg', 'wind_gust',\n",
       "       'rain_1h', 'rain_3h', 'clouds_all', 'datetime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_weather.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918c614a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['primary_road', 'secondary_road', 'lat', 'lon', 'Total'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_traffic.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444fd4a6",
   "metadata": {},
   "source": [
    "Before we start using the collisions coordinates to create our grid boundaries, we need to make sure there are no erroneous locations (which we've already seen in previous notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fac82ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_road</th>\n",
       "      <th>secondary_road</th>\n",
       "      <th>intersection</th>\n",
       "      <th>side_of_highway</th>\n",
       "      <th>severity</th>\n",
       "      <th>type</th>\n",
       "      <th>pedestrian</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>motorcycle</th>\n",
       "      <th>truck</th>\n",
       "      <th>same_day_crashes</th>\n",
       "      <th>same_road_crashes</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [primary_road, secondary_road, intersection, side_of_highway, severity, type, pedestrian, bicycle, motorcycle, truck, same_day_crashes, same_road_crashes, latitude, longitude, datetime]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_collisions[LA_collisions['latitude'] > 35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9916709a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_road</th>\n",
       "      <th>secondary_road</th>\n",
       "      <th>intersection</th>\n",
       "      <th>side_of_highway</th>\n",
       "      <th>severity</th>\n",
       "      <th>type</th>\n",
       "      <th>pedestrian</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>motorcycle</th>\n",
       "      <th>truck</th>\n",
       "      <th>same_day_crashes</th>\n",
       "      <th>same_road_crashes</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300034</th>\n",
       "      <td>HOOVER</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-02-28 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302523</th>\n",
       "      <td>RIVERSIDE</td>\n",
       "      <td>FULTON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-16 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302541</th>\n",
       "      <td>VENTURA                      BL</td>\n",
       "      <td>LA MAIDA                     ST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-14 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302566</th>\n",
       "      <td>VENTURA                      BL</td>\n",
       "      <td>DONNA                        AV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-16 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302671</th>\n",
       "      <td>VAN NUYS                     BL</td>\n",
       "      <td>HUSTON                       ST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-16 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           primary_road                   secondary_road  \\\n",
       "300034                           HOOVER                        JEFFERSON   \n",
       "302523                        RIVERSIDE                           FULTON   \n",
       "302541  VENTURA                      BL  LA MAIDA                     ST   \n",
       "302566  VENTURA                      BL  DONNA                        AV   \n",
       "302671  VAN NUYS                     BL  HUSTON                       ST   \n",
       "\n",
       "        intersection side_of_highway       severity           type  \\\n",
       "300034           0.0   Not Available  Not Available  Not Available   \n",
       "302523           0.0   Not Available  Not Available  Not Available   \n",
       "302541           0.0   Not Available  Not Available  Not Available   \n",
       "302566           0.0   Not Available  Not Available  Not Available   \n",
       "302671           0.0   Not Available  Not Available  Not Available   \n",
       "\n",
       "        pedestrian  bicycle  motorcycle  truck  same_day_crashes  \\\n",
       "300034           0        0           0      0                 0   \n",
       "302523           0        0           0      0                 0   \n",
       "302541           0        0           0      0                 0   \n",
       "302566           0        0           0      0                 0   \n",
       "302671           0        0           0      0                 0   \n",
       "\n",
       "        same_road_crashes  latitude  longitude             datetime  \n",
       "300034                  0       0.0        0.0  2021-02-28 18:00:00  \n",
       "302523                  0       0.0        0.0  2020-04-16 18:00:00  \n",
       "302541                  0       0.0        0.0  2020-04-14 15:00:00  \n",
       "302566                  0       0.0        0.0  2020-04-16 13:00:00  \n",
       "302671                  0       0.0        0.0  2020-04-16 15:00:00  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_collisions[LA_collisions['latitude'] < 33].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69468ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_road</th>\n",
       "      <th>secondary_road</th>\n",
       "      <th>intersection</th>\n",
       "      <th>side_of_highway</th>\n",
       "      <th>severity</th>\n",
       "      <th>type</th>\n",
       "      <th>pedestrian</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>motorcycle</th>\n",
       "      <th>truck</th>\n",
       "      <th>same_day_crashes</th>\n",
       "      <th>same_road_crashes</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [primary_road, secondary_road, intersection, side_of_highway, severity, type, pedestrian, bicycle, motorcycle, truck, same_day_crashes, same_road_crashes, latitude, longitude, datetime]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_collisions[LA_collisions['longitude'] < -119]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfc2aff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_road</th>\n",
       "      <th>secondary_road</th>\n",
       "      <th>intersection</th>\n",
       "      <th>side_of_highway</th>\n",
       "      <th>severity</th>\n",
       "      <th>type</th>\n",
       "      <th>pedestrian</th>\n",
       "      <th>bicycle</th>\n",
       "      <th>motorcycle</th>\n",
       "      <th>truck</th>\n",
       "      <th>same_day_crashes</th>\n",
       "      <th>same_road_crashes</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300034</th>\n",
       "      <td>HOOVER</td>\n",
       "      <td>JEFFERSON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2021-02-28 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302523</th>\n",
       "      <td>RIVERSIDE</td>\n",
       "      <td>FULTON</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-16 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302541</th>\n",
       "      <td>VENTURA                      BL</td>\n",
       "      <td>LA MAIDA                     ST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-14 15:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302566</th>\n",
       "      <td>VENTURA                      BL</td>\n",
       "      <td>DONNA                        AV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-16 13:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302671</th>\n",
       "      <td>VAN NUYS                     BL</td>\n",
       "      <td>HUSTON                       ST</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>Not Available</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-04-16 15:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           primary_road                   secondary_road  \\\n",
       "300034                           HOOVER                        JEFFERSON   \n",
       "302523                        RIVERSIDE                           FULTON   \n",
       "302541  VENTURA                      BL  LA MAIDA                     ST   \n",
       "302566  VENTURA                      BL  DONNA                        AV   \n",
       "302671  VAN NUYS                     BL  HUSTON                       ST   \n",
       "\n",
       "        intersection side_of_highway       severity           type  \\\n",
       "300034           0.0   Not Available  Not Available  Not Available   \n",
       "302523           0.0   Not Available  Not Available  Not Available   \n",
       "302541           0.0   Not Available  Not Available  Not Available   \n",
       "302566           0.0   Not Available  Not Available  Not Available   \n",
       "302671           0.0   Not Available  Not Available  Not Available   \n",
       "\n",
       "        pedestrian  bicycle  motorcycle  truck  same_day_crashes  \\\n",
       "300034           0        0           0      0                 0   \n",
       "302523           0        0           0      0                 0   \n",
       "302541           0        0           0      0                 0   \n",
       "302566           0        0           0      0                 0   \n",
       "302671           0        0           0      0                 0   \n",
       "\n",
       "        same_road_crashes  latitude  longitude             datetime  \n",
       "300034                  0       0.0        0.0  2021-02-28 18:00:00  \n",
       "302523                  0       0.0        0.0  2020-04-16 18:00:00  \n",
       "302541                  0       0.0        0.0  2020-04-14 15:00:00  \n",
       "302566                  0       0.0        0.0  2020-04-16 13:00:00  \n",
       "302671                  0       0.0        0.0  2020-04-16 15:00:00  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_collisions[LA_collisions['longitude'] > -117].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a148d316",
   "metadata": {},
   "source": [
    "Looks like the erroneous locations are all at (0,0). We used the geocoding api quite a bit in the last notebook, so, in the interest of preserving cost, these rows will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afd0b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_collisions = LA_collisions[LA_collisions['latitude'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5706ea81",
   "metadata": {},
   "source": [
    "The factors that are important to the model are temp, visibility, dew point, pressure, humidity, wind speed, wind gust, rain 1h, rain 3h, and clouds all. Thats ten weather variables, the traffic flow data, and the target variable (collision or no collision) over time. To start, with a temporal resolution of 1 hour, how many frames will our data have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ee7a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_weather['datetime'] = pd.to_datetime(LA_weather['datetime'])\n",
    "LA_collisions['datetime'] = pd.to_datetime(LA_collisions['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d807fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2010-01-01 00:00:00')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_collisions.datetime.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf0db45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2023-02-04 08:00:00')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_collisions.datetime.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66268238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2006-12-31 16:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_weather.datetime.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac345c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-12-31 15:00:00')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_weather.datetime.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d56559",
   "metadata": {},
   "source": [
    "The weather data starts earlier, but also ends sooner. Let's drop the extra rows from the two dataframes to make the times matchup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20e3a003",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_weather = LA_weather[LA_weather['datetime'] >= pd.to_datetime('2010-01-01 00:00:00')]\n",
    "LA_collisions = LA_collisions[LA_collisions['datetime'] <= pd.to_datetime('2021-12-31 15:00:00')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cf9c2389",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_weather.sort_values('datetime', ignore_index = True, inplace = True)\n",
    "LA_collisions.sort_values('datetime', ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e68f65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('4382 days 15:00:00')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_weather.datetime.max() - LA_weather.datetime.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0a08384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105183"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(4382 * 24) + 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "873f8e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103273"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_weather.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efc4472",
   "metadata": {},
   "source": [
    "There's going to be over 100,000 frames of data. However, there are obviously some missing times in our weather data, almost 2000. Let's see if we can input those missing times rows. The time will be handled first and the weather features can be handled after with .fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b3a5128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx in range(1, 105184):\n",
    "    if ((LA_weather['datetime'][idx] - LA_weather['datetime'][idx - 1]) != pd.to_timedelta('0 days 01:00:00')):\n",
    "        idxs = np.split(LA_weather.index, [idx])\n",
    "        LA_weather.set_index(idxs[0].union(idxs[1] + 1), inplace = True)\n",
    "        LA_weather.loc[idx] = [np.NAN] * LA_weather.shape[1]\n",
    "        LA_weather['datetime'][idx] = LA_weather['datetime'][idx - 1] + pd.to_timedelta('01:00:00')\n",
    "        LA_weather.sort_values('datetime', ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cd129c",
   "metadata": {},
   "source": [
    "Now that the missing times are imputed, we can sort by the datetime and fill in the missing weather variables using pad or backfill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea1c691d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt            1911\n",
       "temp          1911\n",
       "visibility    1911\n",
       "dew_point     1911\n",
       "temp_min      1911\n",
       "temp_max      1911\n",
       "pressure      1911\n",
       "humidity      1911\n",
       "wind_speed    1911\n",
       "wind_deg      1911\n",
       "wind_gust     1911\n",
       "rain_1h       1911\n",
       "rain_3h       1911\n",
       "clouds_all    1911\n",
       "datetime         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_weather.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c0961cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_weather.sort_values('datetime', ignore_index = True, inplace = True)\n",
    "LA_weather.fillna(method = 'pad', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "284c420e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dt            0\n",
       "temp          0\n",
       "visibility    0\n",
       "dew_point     0\n",
       "temp_min      0\n",
       "temp_max      0\n",
       "pressure      0\n",
       "humidity      0\n",
       "wind_speed    0\n",
       "wind_deg      0\n",
       "wind_gust     0\n",
       "rain_1h       0\n",
       "rain_3h       0\n",
       "clouds_all    0\n",
       "datetime      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_weather.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ace51d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105184"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_weather.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b2e02c",
   "metadata": {},
   "source": [
    "Now, just to make sure that the weather dataframe is sorted by the datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04654455",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_weather.sort_values('datetime', ignore_index = True, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d5a8b",
   "metadata": {},
   "source": [
    "We can now start creating the tensor. While the weather dataframe has a temporal component, it has no spatial component. The historical weather data was retrieved only for a single coordinate in the center of Los Angeles in order to preserve cost. That makes the nd-array creation much easier for those features. <br>\n",
    "The collisions dataframe and the weather dataframe have the same start and end datetime. This, and the fact that each time index represents one hour from the previous, means that to find the temporal index of the row in the collisions dataframe, we need only to subtract the minimum datetime from the corresponding datetime and record the number of hours. The latitude and longitude values can be found in the same way as the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "597284e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_grid = np.zeros((LA_weather.shape[0],50,30,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7dfdec12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lats, lats_step = np.linspace(\n",
    "    LA_traffic['lat'].max(), LA_collisions['latitude'].min(), num = 50, retstep = True)\n",
    "lons, lons_step = np.linspace(\n",
    "    LA_traffic['lon'].min(), LA_collisions['longitude'].max(), num = 30, retstep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b26c8429",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(LA_weather.shape[0]):\n",
    "        LA_grid[idx,:,:,2] = LA_weather['temp'][idx]\n",
    "        LA_grid[idx,:,:,3] = LA_weather['visibility'][idx]\n",
    "        LA_grid[idx,:,:,4] = LA_weather['humidity'][idx]\n",
    "        LA_grid[idx,:,:,5] = LA_weather['rain_1h'][idx]\n",
    "        LA_grid[idx,:,:,6] = LA_weather['rain_3h'][idx]\n",
    "        LA_grid[idx,:,:,7] = LA_weather['clouds_all'][idx]\n",
    "        LA_grid[idx,:,:,8] = LA_weather['pressure'][idx]\n",
    "        LA_grid[idx,:,:,9] = LA_weather['wind_speed'][idx]\n",
    "        LA_grid[idx,:,:,10] = LA_weather['wind_gust'][idx]\n",
    "        LA_grid[idx,:,:,11] = LA_weather['dew_point'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "de78fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_idxs = (LA_traffic['lat'] - LA_traffic['lat'].max()) / lats_step\n",
    "lon_idxs = (LA_traffic['lon'] - LA_traffic['lon'].min()) / lons_step\n",
    "for idx in range(lat_idxs.shape[0]):\n",
    "    lat_idx = abs(math.floor(lat_idxs.iloc[idx]))\n",
    "    lon_idx = abs(math.floor(lon_idxs.iloc[idx]))\n",
    "    LA_grid[:,lat_idx,lon_idx,1]  = LA_traffic['Total'][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "82302b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_collisions['lat_idxs'] = (LA_collisions['latitude'] - LA_traffic['lat'].max()) / lats_step\n",
    "LA_collisions['lon_idxs'] = (LA_collisions['longitude'] - LA_traffic['lon'].min()) / lons_step\n",
    "LA_collisions['time_idxs'] = (LA_collisions['datetime'] - LA_collisions['datetime'].min())\n",
    "LA_collisions['time_idxs'] = LA_collisions['time_idxs'].dt.components['days'] * 24 + LA_collisions['time_idxs'].dt.components['hours']\n",
    "for idx in range(LA_collisions.shape[0]):\n",
    "    lat_idx = abs(math.floor(LA_collisions['lat_idxs'][idx]))\n",
    "    lon_idx = abs(math.floor(LA_collisions['lon_idxs'][idx]))\n",
    "    time_idx = math.floor(LA_collisions['time_idxs'][idx])\n",
    "    LA_grid[time_idx,lat_idx,lon_idx,0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7ae486d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105184, 50, 30, 12)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_grid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caaf4c7c",
   "metadata": {},
   "source": [
    "Now that all of the grids have been created, we can split the data into test and train data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2de57e",
   "metadata": {},
   "source": [
    "### 6 Split the Data<a id='6_Split_the_Data'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceda4341",
   "metadata": {},
   "source": [
    "It is expected that the temporal aspect of the data will be important to model performance. Specifically, we want the model to be able to predict the accidents occuring in the next hour based on the weather and traffic data at the time and the weather,traffic, and accident data at the current time. For this reason, a random split of the data will lose the temporal clarity that our model will need to make accurate predictions about the future. So, a single split will be made such that 75% of the data will make up the training data, consisting of data from the start date to the split date, and the remaining 25% of the date will be the test data, consisting of data from the split date to the end date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "812d3b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ind = math.floor(LA_grid.shape[0] * 0.75)\n",
    "LA_train = LA_grid[:split_ind,:,:,:]\n",
    "LA_test = LA_grid[split_ind:,:,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "24214640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((78888, 50, 30, 12), (26296, 50, 30, 12))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LA_train.shape, LA_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011c817d",
   "metadata": {},
   "source": [
    "### 7 Saving as an H5PY File <a id='7_Saving_as_an_H5PY_File'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ac20d7",
   "metadata": {},
   "source": [
    "We can now store those two arrays as datasets in an h5py file. This will allow us to clear our memory of those datasets, which will make the next step possible, creating new datasets from windows of the old ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65fbfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_data_split = h5py.File('../Data/LA_data_split.hdf5','w-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06a9b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_data_split.create_dataset('train', data = LA_train, chunks = (32,50,30,12), compression=\"gzip\");\n",
    "LA_data_split.create_dataset('test', data = LA_test, chunks = (32,50,30,12), compression=\"gzip\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc6a1778",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_data_split.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "de35c8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del LA_train\n",
    "del LA_test\n",
    "del LA_grid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730b19c",
   "metadata": {},
   "source": [
    "### 8 Creating Windowed Datasets <a id='8_Creating_Windowed_Datasets'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de74422c",
   "metadata": {},
   "source": [
    "I am now going to create a windowed dataset using the H5PY file just created. The window will be of size 2. After, I will make a new H5PY file for the windowed datasets, which will be used in the modeling notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5888507",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_windowed_split = h5py.File('../Data/LA_windowed_split.hdf5','w-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2124346",
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5dataset(dt.Dataset):\n",
    "    def __init__(self, h5_path, set_name):\n",
    "        self.h5 = h5py.File(h5_path, 'r')\n",
    "        self.set = self.h5[set_name]\n",
    "        self.chunk_dict = {}\n",
    "        for ch, sl in enumerate(self.set.iter_chunks()):\n",
    "            self.chunk_dict[ch] = sl\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.set.shape[0]\n",
    "    \n",
    "    def __getitem__(self, chunk, chunk_idx):\n",
    "        sample = self.set[self.chunk_dict[chunk]][chunk_idx]\n",
    "        return t.tensor(sample)\n",
    "    \n",
    "    def CLOSE(self):\n",
    "        self.h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e48078a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = H5dataset('../Data/LA_data_split.hdf5', 'train')\n",
    "test_data = H5dataset('../Data/LA_data_split.hdf5', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc007acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window(dataset, start, end):\n",
    "    chunk = math.floor(start / 32)\n",
    "    chunk_idx = start%32\n",
    "    windows = []\n",
    "    for idx in range(start, end+1):\n",
    "        window = dataset.__getitem__(chunk, chunk_idx)\n",
    "        chunk_idx += 1\n",
    "        if (chunk_idx == 32):\n",
    "            chunk += 1\n",
    "            chunk_idx = 0\n",
    "        windows.append(window)\n",
    "    window_tensor = t.stack(windows)\n",
    "    return window_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a461b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windowed_dataset(dataset, lookback):\n",
    "    windows = []\n",
    "    for i in range(len(dataset) - lookback):\n",
    "        window = get_window(dataset, i, i+lookback)\n",
    "        windows.append(window)\n",
    "    windowed_dataset = t.stack(windows)\n",
    "    return windowed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb4d057",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_windowed = create_windowed_dataset(train_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbe061de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([78883, 6, 50, 30])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windowed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88867c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_windowed_split.create_dataset('train_windowed', data = train_windowed, chunks = (32,2,50,30,12), compression=\"gzip\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49c4c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.CLOSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e3e3224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train_windowed\n",
    "del train_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a1cf1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_windowed = create_windowed_dataset(test_data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecb61616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26291, 6, 50, 30])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_windowed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b0965c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_windowed_split.create_dataset('test_windowed', data = test_windowed, chunks = (32,2,50,30,12), compression=\"gzip\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a540f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.CLOSE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f42629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_windowed\n",
    "del test_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9b8b144",
   "metadata": {},
   "outputs": [],
   "source": [
    "LA_windowed_split.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cba8281",
   "metadata": {},
   "source": [
    "### 9 Conclusion<a id='9_Conclusion'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b02e844",
   "metadata": {},
   "source": [
    "In this notebook, we created the tensor that will be used for modeling , split the data, and created an h5py file to hold that split data. The data was split 75/25. We then created windowed datasats for our train and test sets.. FInally, another H5PY file was created to hold the windowed datasets for use in modeling.\n",
    "\n",
    "We are now going to move into the modeling phase of the project in the following notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
